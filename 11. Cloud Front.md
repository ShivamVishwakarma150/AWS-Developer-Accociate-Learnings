# Amazon CloudFront: Overview and Use Cases

**Amazon CloudFront** is a Content Delivery Network (CDN) that enhances the performance of delivering content to users by caching copies of your content at various edge locations globally. This results in reduced latency and improved user experience.

#### Key Features and Benefits

1. **Global Distribution and Edge Locations:**
   - CloudFront has 216 points of presence (edge locations) worldwide.
   - These edge locations cache your content, ensuring that users can access it quickly from the nearest location.

2. **Improved Performance:**
   - By caching content closer to users, CloudFront significantly reduces latency.
   - This is beneficial for static and dynamic content, including web pages, images, videos, and APIs.

3. **Security Enhancements:**
   - Provides DDoS protection by distributing traffic across multiple locations.
   - Integrates with AWS Shield and AWS Web Application Firewall (WAF) for additional security.

4. **Origin Support:**
   - CloudFront supports multiple origin types, such as Amazon S3 buckets, custom HTTP servers, and AWS services like Application Load Balancers and EC2 instances.
   - Utilizes Origin Access Control (OAC) to ensure only CloudFront can access your S3 bucket, replacing the older Origin Access Identity (OAI).

5. **Caching Mechanism:**
   - When a user requests content, CloudFront first checks its cache at the nearest edge location.
   - If the content is not cached, CloudFront fetches it from the origin, caches it, and serves it to the user.

6. **Private and Secure Access:**
   - CloudFront can serve content securely using HTTPS.
   - You can use signed URLs and signed cookies to restrict access to your content.

#### CloudFront and S3 Integration

- **S3 as an Origin:** 
  - Content stored in an S3 bucket can be distributed globally using CloudFront.
  - Users access the content from the nearest edge location, reducing the load on your S3 bucket and ensuring faster delivery.

- **Origin Access Control (OAC):**
  - Ensures that only CloudFront can access your S3 bucket.
  - Requires updating the bucket policy to allow access via CloudFront.

- **Caching at Edge Locations:**
  - Content is cached at edge locations for a specified duration, typically around a day.
  - Subsequent requests for the same content are served directly from the edge location, reducing latency.

#### CloudFront vs. S3 Cross-Region Replication

- **CloudFront:**
  - Uses a global edge network with over 216 points of presence.
  - Content is cached at edge locations, ideal for static content that needs global availability.
  - Provides DDoS protection and improved security features.
  
- **S3 Cross-Region Replication:**
  - Must be configured for each specific region.
  - Updates files in near real-time, suitable for dynamic content.
  - Ensures low-latency access in specified regions but does not provide global caching like CloudFront.

#### Use Case Example

1. **Static Website Hosting:**
   - Host your static website on an S3 bucket.
   - Use CloudFront to cache and distribute your website globally.
   - Improve load times for users by serving cached content from edge locations.

2. **Media Streaming:**
   - Deliver videos and other media content using CloudFront.
   - Reduce buffering and improve playback performance by caching content at edge locations.

3. **API Acceleration:**
   - Use CloudFront to accelerate API responses by caching API responses at edge locations.
   - Decrease latency and improve the performance of your API services.

### Summary

Amazon CloudFront enhances the performance and security of content delivery by caching content at multiple global edge locations. It integrates seamlessly with various AWS services, including S3, and supports a range of use cases from static website hosting to media streaming and API acceleration. CloudFrontâ€™s global distribution, caching mechanism, and security features make it an essential tool for delivering high-performance, secure content to users worldwide.


<br/>
<br/>

# Practical Guide to Setting Up Amazon CloudFront with an S3 Bucket

Here's a step-by-step guide to setting up Amazon CloudFront for your S3 bucket to make files accessible without making them public.

#### Step 1: Create an S3 Bucket and Upload Files

1. **Create an S3 Bucket:**
   - Go to the S3 console.
   - Click on "Create bucket".
   - Name your bucket (e.g., `demo-cloudFront-stephane-V4`).
   - Leave the default settings and click "Create bucket".

2. **Upload Files:**
   - Open the newly created bucket.
   - Click "Upload" and add files (e.g., `beach.jpeg`, `coffee.jpeg`, `index.html`).
   - Confirm the upload.

#### Step 2: Verify File Accessibility

1. **Accessing Files:**
   - Try accessing `index.html` using the object URL. It will be denied because the object is not public.
   - Open the file using the S3 console which generates a pre-signed URL, allowing access.

#### Step 3: Set Up CloudFront Distribution

1. **Open CloudFront Console:**
   - Go to the CloudFront console. Note that CloudFront is a global service.

2. **Create a Distribution:**
   - Click "Create distribution".
   - In the "Origin domain" field, select your S3 bucket (`demo-cloudFront-stephane-V4`).
   - Under "Origin access", select "Origin access control (OAC)" and create a new origin access control setting.
   - Give it a name and create it.

3. **Update S3 Bucket Policy:**
   - After creating the origin access control, you need to update your S3 bucket policy to allow CloudFront access.
   - Copy the policy provided by CloudFront.
   - Go to your S3 bucket, open "Permissions" > "Bucket policy", and paste the copied policy.
   - Save the policy changes.

4. **Configure Default Root Object:**
   - Set the default root object to `index.html`.

5. **Create Distribution:**
   - Finish the setup by creating the distribution. This process may take a few minutes.

#### Step 4: Verify CloudFront Distribution

1. **Accessing via CloudFront:**
   - Once the distribution is deployed, copy the CloudFront domain name.
   - Open a new browser tab and access the domain. You should see the content of `index.html`.
   - Access other files like `/coffee.jpeg` and `/beach.jpeg` using the CloudFront domain.

2. **Cache Verification:**
   - Refresh the page to see faster load times, indicating that the content is served from the CloudFront cache instead of directly from S3.

#### Step 5: CloudFront Management

1. **Managing Origins and Controls:**
   - In the CloudFront console, you can manage your origins and access controls.
   - Verify that the origin access control is active and assigned to your distribution.

By following these steps, you have successfully set up an Amazon CloudFront distribution for your S3 bucket, enabling secure, cached access to your files without making them public. This setup leverages CloudFront's global edge locations for fast content delivery and added security features.


<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>

# Understanding Caching in CloudFront

#### How CloudFront Caching Works

1. **Edge Locations and Cache:**
   - CloudFront caches content at each of its edge locations globally.
   - Each cache at an edge location stores objects identified by a unique Cache Key.
   - When a request is made to an edge location, it first checks the cache for the object.

2. **Cache Checks:**
   - The edge location verifies if the object is in the cache and if it has expired based on the Time to Live (TTL) setting.
   - If the object is not in the cache or has expired, the request is forwarded to the origin server.

3. **Response and Cache:**
   - The response from the origin server is cached at the edge location.
   - Future requests for the same object are served from the cache, improving performance and reducing origin load.

4. **Maximizing Cache Hit Ratio:**
   - To optimize performance, maximize the Cache Hit ratio by caching as much content as possible.
   - You can create cache invalidations to remove objects from the cache before they expire.

#### CloudFront Cache Key

1. **Cache Key Composition:**
   - A Cache Key uniquely identifies each object in the cache.
   - By default, it consists of the host name and the resource portion of the URL.
   - Example: For the URL `https://mywebsite.com/content/stories/example-story.html`, the Cache Key includes:
     - Host name: `mywebsite.com`
     - Resource: `/content/stories/example-story.html`

2. **Enhanced Cache Keys:**
   - Cache Keys can be customized to include additional parameters like HTTP headers, cookies, or query strings.
   - This is done by defining a CloudFront cache policy.

#### CloudFront Cache Policy

1. **Components of Cache Policy:**
   - **HTTP Headers:** Select which headers to include in the Cache Key (none, whitelist, or all).
   - **Cookies:** Choose which cookies to include (none, whitelist, all, or all except).
   - **Query Strings:** Decide which query strings to include (none, whitelist, all, or all except).

2. **TTL Control:**
   - Cache policy also controls the TTL, ranging from 0 seconds up to 1 year.
   - TTL can also be managed using the `Cache-Control` or `Expires` headers.

3. **AWS Managed Policies:**
   - AWS provides predefined managed cache policies or you can create your own custom policies.

#### Forwarding to Origin

1. **Origin Request Policy:**
   - An origin request policy specifies additional HTTP headers, cookies, or query strings that should be forwarded to the origin but not included in the Cache Key.
   - This helps in cases where the origin server needs more information than what is used for caching.

2. **Custom Headers:**
   - You can add custom HTTP headers to the origin request for specific needs, such as passing an API key.

3. **Example of Forwarding:**
   - A request might include language headers to serve content in a specific language. If you include this header in the Cache Key, it will also be forwarded to the origin.

#### Key Differences

1. **Cache Policy vs. Origin Request Policy:**
   - **Cache Policy:** Determines what is included in the Cache Key and thus what variations are cached.
   - **Origin Request Policy:** Specifies additional information to send to the origin but not used for caching.

#### Summary

- CloudFront caches content at edge locations to reduce latency and origin load.
- Cache Keys are unique identifiers for cached objects, typically based on URL components.
- Cache policies define how Cache Keys are created, including optional headers, cookies, and query strings.
- Origin request policies allow forwarding additional information to the origin server without affecting the cache.
- Combining cache policies and origin request policies optimizes both caching efficiency and origin server functionality.

<br/>
<br/>

# Cache Invalidations in CloudFront

#### Concept and Need for Cache Invalidations

- **Background:**
  - CloudFront serves cached content from its edge locations to reduce latency and improve performance.
  - When the backend origin is updated, CloudFront's edge locations are unaware of these updates until the cache's Time to Live (TTL) expires.

- **Issue:**
  - Waiting for TTL to expire might be undesirable when updated content needs to be served immediately.

- **Solution:**
  - **Cache Invalidation:** 
    - Forces a refresh of specific or entire cached content before TTL expires.
    - Eliminates outdated content from the cache, ensuring that the latest content is served from the origin.

#### How to Perform Cache Invalidations

1. **Invalidation Request:**
   - You specify the file paths you want to invalidate.
   - You can invalidate:
     - **Specific files:** By providing the exact path, e.g., `/index.html`.
     - **All files in a directory:** Using wildcard characters, e.g., `/images/*`.

2. **Example Scenario:**

   - **Setup:**
     - A CloudFront distribution with two edge locations.
     - Each edge location caches `index.html` and images from an S3 bucket.
     - TTL for these files is set to one day.

   - **Update:**
     - An admin updates files in the S3 bucket, adding or changing images and modifying `index.html`.
     - These updates need to be reflected immediately.

   - **Invalidation Process:**
     - The admin requests invalidation for:
       - `/index.html` to invalidate the specific file.
       - `/images/*` to invalidate all images in the directory.

   - **Effect:**
     - CloudFront communicates with edge locations to remove these files from their caches.
     - When a user requests `index.html` or any image:
       - CloudFront forwards the request to the edge location.
       - The edge location finds the file is not in the cache.
       - The edge location fetches the updated file from the origin (S3 bucket).

   - **Result:**
     - The user receives the updated content immediately without waiting for the original TTL to expire.

#### Benefits of Cache Invalidations

- Ensures that users receive the most current content without delay.
- Provides flexibility in content management by allowing partial or complete cache refresh.
- Enhances user experience by reducing latency in content updates.

#### Summary

- **Cache Invalidation:** A critical feature in CloudFront for refreshing cached content before TTL expires.
- **Usage:** Specify paths for invalidation to ensure edge locations fetch the latest content from the origin.
- **Impact:** Improves content delivery and user satisfaction by serving updated content promptly.

<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>

# Cache Behaviors in CloudFront

#### Concept of Cache Behaviors

- **Purpose:**
  - Allows different origins and caches for different URL path patterns.
  - Enables specific handling of various content types or paths.

- **Example Use Cases:**
  - Route all JPEG images to a web server.
  - Route API requests to an application load balancer.
  - Default behavior for all other content types.

#### Configuration of Cache Behaviors

1. **Defining Cache Behaviors:**
   - Specific paths can be directed to different origins.
   - Example:
     - `/api/*` â†’ Application load balancer.
     - `/images/*` â†’ S3 bucket.
     - `/*` (default) â†’ Another S3 bucket or different origin.

2. **Default Cache Behavior:**
   - Always represented by `/*`.
   - Acts as a fallback for any request that doesn't match other specific patterns.
   - Last to be processed if no specific match is found.

#### Example Scenario

- **Setup:**
  - Two cache behaviors:
    - `/api/*` â†’ Application load balancer.
    - `/*` â†’ S3 bucket.

- **Operation:**
  - Users requesting `/api/*` are directed to the application load balancer.
  - Users requesting any other path are directed to the S3 bucket.

#### Use Cases for Cache Behaviors

1. **Gating Access to S3 Bucket:**
   - **Scenario:**
     - Require users to sign in via a login page before accessing S3 content.
   - **Implementation:**
     - Define cache behavior for `/login`:
       - Redirects users to an EC2 instance for login.
       - EC2 instance generates CloudFront signed cookies.
     - Users use signed cookies to access the default cache behavior.
     - Requests to the default cache behavior without signed cookies redirect to the login page.

2. **Maximizing Cache Hit:**
   - **Scenario:**
     - Different cache strategies for static and dynamic content.
   - **Implementation:**
     - **Static Content:**
       - Route static requests (e.g., images, CSS, JS) to an S3 bucket.
       - No complex cache policy; maximize cache hits based on resource path.
     - **Dynamic Content:**
       - Route dynamic requests (e.g., API calls) to a load balancer and EC2 instances.
       - Use cache policies that include relevant headers and cookies.

#### Summary

- **Cache Behaviors:**
  - Allow specific routing based on URL patterns.
  - Enable distinct handling and caching strategies for different content types.
  - Improve efficiency and user experience by directing requests to appropriate origins.

- **Key Points:**
  - Different behaviors can be defined for different paths.
  - Default behavior acts as a catch-all.
  - Useful for access control and optimizing cache performance for various content types.

<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>

# CloudFront Caching Behavior and Invalidation

#### Overview

- **Default Behavior:** 
  - Set by default to `*`, meaning it handles all requests unless overridden by more specific behaviors.
  - Cannot edit the path pattern for the default behavior.

#### Cache Policies

1. **Creating a Cache Policy:**
   - **Name:** Example - `DemoCachePolicy`.
   - **Time-to-Live (TTL) Settings:**
     - **Minimum TTL:** The shortest duration to cache an object.
     - **Maximum TTL:** The longest duration to cache an object.
     - **Default TTL:** The default duration to cache an object if no other directives are present.
   - **Cache Key Settings:**
     - **Headers:** Select specific headers to include in the cache key.
     - **Query Strings:** Choose to include all, none, or specific query strings.
     - **Cookies:** Choose to include all, none, or specific cookies.
   - **Impact:** These settings determine how content is cached and ensure that the specified headers, query strings, and cookies are passed to the origin request.

2. **Origin Request Policies:**
   - **Purpose:** Adds extra headers, query strings, or cookies to the origin request without affecting the cache key.
   - **Example:** 
     - Name: `DemoOriginPolicy`.
     - Specify additional headers, query strings, and cookies to include in the request to the origin.

#### Implementing Cache Behaviors

- **Adding a New Behavior:**
  - Example: Create a behavior for `/images/*` to route requests to a specific origin, such as another S3 bucket or an EC2 instance.
  - **Cache Policy and Origin Request Policy:** Each behavior can have its own cache policy and origin request policy.

- **Order of Processing:**
  - Specific cache behaviors are processed before the default behavior. 
  - The default behavior (`/*`) acts as a fallback for requests that do not match any specific patterns.

#### Practical Example

1. **Updating Content:**
   - Update `index.html` file to change the content from "I really love coffee" to "I really love coffee every morning".
   - Upload the updated file to the S3 bucket.

2. **Cache Invalidation:**
   - **Problem:** CloudFront continues to serve the old version of `index.html` due to its cached copy.
   - **Solution:**
     - Navigate to the invalidations tab in CloudFront.
     - Create a new invalidation for the path `/*` to remove all objects from the cache.
     - Once the invalidation completes, CloudFront fetches the updated `index.html` from S3.

#### Conclusion

- **Cache Policies and Origin Request Policies:** 
  - Define how CloudFront caches and forwards requests.
  - Cache policy affects caching behavior; origin request policy adds additional request parameters.
  
- **Cache Invalidation:**
  - Necessary to ensure updated content is served immediately.
  - Performed by creating invalidations to clear cached objects.

This process helps manage and control content delivery effectively, ensuring users receive the most up-to-date content while optimizing caching for performance.

<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>

# Accessing Custom HTTP Backends with CloudFront

CloudFront can be configured to access custom HTTP backends, such as an EC2 instance or an application load balancer (ALB). Here's how to set this up:

#### 1. Using an EC2 Instance

- **Public Accessibility:** 
  - The EC2 instance must be publicly accessible since CloudFront edge locations require public access to communicate with your backend.
  
- **Security Group Configuration:**
  - You need to allow the public IP addresses of CloudFront edge locations in the security group of your EC2 instance. This ensures that only requests from CloudFront are permitted.
  - The list of CloudFront IPs can be found [here](https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/LocationsOfEdgeServers.html).

- **Workflow:**
  - Users send requests to CloudFront edge locations.
  - The edge locations forward these requests to your public EC2 instance.

#### 2. Using an Application Load Balancer (ALB)

- **Public ALB and Private EC2 Instances:**
  - The ALB must be public to receive requests from CloudFront edge locations.
  - Backend EC2 instances can be private, as the ALB provides private VPC connectivity to them.
  
- **Security Group Configuration:**
  - The security group of the ALB should allow inbound traffic from the public IP addresses of CloudFront edge locations.
  - The security group of the backend EC2 instances should allow inbound traffic from the security group of the ALB.

- **Workflow:**
  - Users send requests to CloudFront edge locations.
  - The edge locations forward these requests to the public ALB.
  - The ALB routes the requests to the private EC2 instances.

### Summary

- **Direct EC2 Setup:**
  - EC2 instance must be public.
  - Security group of EC2 must allow traffic from CloudFront edge IPs.

- **ALB Setup:**
  - ALB must be public, backend EC2 instances can be private.
  - Security group of ALB must allow traffic from CloudFront edge IPs.
  - Security group of backend EC2 instances must allow traffic from the ALB's security group.

By following these configurations, you can securely route traffic from CloudFront to your custom HTTP backends, ensuring proper access and security management.

<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>

# CloudFront Geo Restriction

CloudFront allows you to restrict access to your distribution based on the country from which the request originates. This can be useful for adhering to copyright laws or other regional content restrictions.

#### How Geo Restriction Works

- **Allowlist:** 
  - You can define a list of approved countries that are allowed to access your distribution.
  
- **Blocklist:** 
  - Alternatively, you can define a list of banned countries that are not allowed to access your distribution.
  
- **Geo-IP Database:**
  - The country of the user is determined using a third-party Geo-IP database, which matches the user's IP address to their country.

#### Use Case

- **Copyright Laws:**
  - Restrict access to content to comply with regional copyright laws.

#### Setting Up Geo Restriction

1. **Navigate to Security Settings:**
   - Go to the CloudFront distribution settings and find the security section.
   
2. **Enable Geographic Restrictions:**
   - Under the security settings, find and click on "CloudFront geographic restrictions."
   
3. **Configure Allowlist or Blocklist:**
   - Click on "Edit" to set up either an allowlist or a blocklist.
   - For an allowlist, enumerate the countries that are permitted to access the distribution.
   - For a blocklist, list the countries that should be restricted from accessing the distribution.

#### Example

- **Allowlist Example:**
  - Suppose you want only users from India and the United States to access your distribution.
  - Set up an allowlist with India and the United States listed.
  - Save the changes.

This configuration ensures that only requests originating from India and the United States will be allowed to access your CloudFront distribution, while requests from other countries will be blocked.

This is a basic overview of how to set up and use geo restriction in CloudFront for managing access based on geographic locations.

<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>

# Access Control with CloudFront Signed URLs and Signed Cookies

When you want to provide private access to premium paid content via CloudFront, you can use CloudFront signed URLs or signed cookies. This allows you to control who accesses your content and track that access.

#### CloudFront Signed URLs and Signed Cookies

- **Policy Attachment:** Both signed URLs and cookies require a policy specifying:
  - Expiration time
  - Permitted IP ranges
  - Trusted signers (AWS accounts authorized to create signed URLs)

- **Duration:** 
  - For short-term access (e.g., streaming media), URLs can be valid for a few minutes.
  - For long-term access (e.g., private user content), URLs or cookies can last for years.

#### Differences Between Signed URLs and Signed Cookies

- **Signed URLs:**
  - Provide access to individual files.
  - Require a separate URL for each file (e.g., 100 files require 100 URLs).
  - Ideal for scenarios where users access a few specific files.

- **Signed Cookies:**
  - Provide access to multiple files through a single cookie.
  - Suitable for scenarios where users need access to many files.

#### How Signed URLs Work

1. **Client Authorization:** Clients authenticate with your application.
2. **URL Generation:** The application uses the AWS SDK to generate a signed URL from CloudFront.
3. **URL Usage:** The signed URL is returned to the client.
4. **Access Content:** The client uses the signed URL to access content from CloudFront.

#### Using Signed URLs with Different Origins

- **CloudFront Signed URLs:** 
  - Can grant access to content regardless of the origin type (e.g., S3, HTTP backend).
  - Managed with account-wide key-pairs by the root account.
  - Can include filters for IP, path, date, and expiration.
  - Leverage CloudFrontâ€™s caching capabilities.

- **S3 Pre-signed URLs:**
  - Grant access directly to S3 objects.
  - Signed using the IAM principalâ€™s credentials, giving the same permissions as the signer.
  - Have a limited lifetime.
  - Suitable for direct S3 access without CloudFront.

#### Example Scenario

- **CloudFront with S3 Origin:**
  - Clients request content from CloudFront using signed URLs.
  - CloudFront fetches content from an S3 bucket.
  - S3 bucket policies restrict direct access, allowing access only through CloudFront (via OAC/OAI).

- **CloudFront with HTTP Backend:**
  - Clients use signed URLs to access an HTTP backend through CloudFront.
  - CloudFront forwards requests to an HTTP server or EC2 instance.

#### Practical Use

- **Generate Signed URLs/Cookies:**
  - Use AWS SDKs to create signed URLs or cookies in your application backend.
  - Set appropriate policies for expiration, IP ranges, and trusted signers.

- **Access Control:**
  - Configure CloudFront to restrict content access based on signed URLs or cookies.
  - Ensure that S3 bucket policies allow access only via CloudFront when using CloudFront distributions with S3 origins.

In summary, CloudFront signed URLs and signed cookies are powerful tools for controlling access to private content, providing flexibility in terms of duration and specificity of access. Choose the method that best fits your use case based on the number of files and the type of origin.


<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>

# Generating Keys to Sign URLs with CloudFront

When using CloudFront to control access to content through signed URLs or signed cookies, it is crucial to manage keys for signing URLs securely and efficiently. There are two methods for generating and managing these keys: the older method using a CloudFront key pair and the newer recommended method using a trusted key group.

#### Trusted Key Group (Recommended Method)

1. **Create a Trusted Key Group:**
   - A trusted key group allows you to manage keys more securely and efficiently using IAM policies and APIs for automation.
   - You can create multiple trusted key groups within your CloudFront distribution.

2. **Generate RSA Key Pair:**
   - Generate a private and public RSA key pair with a key size of 2048 bits.
   - Keep the private key secure and private; this will be used by your applications (e.g., EC2 instances) to sign URLs.
   - The public key will be uploaded to CloudFront to verify the signatures of the URLs.

3. **Upload Public Key to CloudFront:**
   - In the CloudFront console, navigate to the "Public Keys" section.
   - Create a new public key, name it (e.g., "demo key"), and paste the public key generated.
   - Ensure the key size is 2048 bits.

4. **Create a Key Group:**
   - In the CloudFront console, navigate to the "Key Groups" section.
   - Create a new key group (e.g., "demo key group").
   - Add the public key to this key group.
   - This key group will be referenced by CloudFront to allow your applications to create signed URLs.

#### Using Keys to Sign URLs

- **Private Key Usage:**
  - The private key is used by your application servers (such as EC2 instances) to generate signed URLs.
  - This key should be stored securely and not exposed publicly.

- **Public Key Verification:**
  - The public key, uploaded to CloudFront, is used to verify the signatures of the URLs generated by your applications.
  - This ensures that only URLs signed by your trusted key pairs are accepted by CloudFront.

#### Old Method: CloudFront Key Pair (Not Recommended)

1. **Root Account Requirement:**
   - The old method requires using the root account credentials, which is not recommended for security reasons.

2. **Create Key Pair in AWS Management Console:**
   - Log in as the root user.
   - Navigate to "My Security Credentials" under your account settings.
   - In the "CloudFront Key Pairs" section, create a new key pair.
   - Download the private key file and public key file.

3. **Use Key Pair to Sign URLs:**
   - The private key is used by your applications to sign URLs.
   - This method lacks automation support via APIs and is less secure due to the requirement of root account usage.

### Summary

The recommended method for generating and managing keys to sign URLs with CloudFront is to use trusted key groups. This method allows for better security practices and automation using IAM policies and APIs. The older method, which relies on CloudFront key pairs managed by the root account, is less secure and not recommended. 

By using trusted key groups and managing keys securely, you can ensure that only authorized users can access your content through CloudFront.

<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>

# Advanced Options for CloudFront

#### 1. Pricing and Price Classes

CloudFront pricing varies based on the geographic region of the edge location from which data is served. Here's a breakdown of how pricing can differ:

- **Pricing Based on Geographic Region:**
  - Data transfer costs vary by continent or region.
  - For example, data transfer in North America (e.g., US, Canada, Mexico) might cost $0.08 per GB for the first 10 TB, whereas in India it could cost $0.17 per GB for the same amount.

- **Volume Discounts:**
  - The more data you transfer out of CloudFront, the lower the cost per GB becomes. For instance, transferring over 5 PB can reduce the cost to $0.02 per GB.

- **Price Classes:**
  - Price classes allow you to choose which CloudFront edge locations are used, affecting both performance and cost.
  - There are three price classes:
    - **Price Class All:** Includes all CloudFront edge locations worldwide, offering the best performance but at a higher cost due to varying data transfer rates.
    - **Price Class 200:** Includes most edge locations, excluding the most expensive ones (e.g., some regions in Asia and South America).
    - **Price Class 100:** Includes only the least expensive edge locations, providing cost savings but potentially impacting performance in certain regions.

#### 2. Multiple Origins and Origin Groups

- **Multiple Origins:**
  - CloudFront supports routing requests to different origins based on the content type or path.
  - For example, you can configure different cache behaviors for paths like `/images/*` to fetch content from an S3 bucket and `/api/*` to fetch content from an Application Load Balancer.

- **Origin Groups:**
  - Origin groups are used for high availability and failover scenarios.
  - Each origin group consists of a primary and a secondary origin.
  - If the primary origin fails to respond or returns an error, CloudFront automatically retries the request with the secondary origin.
  - This setup is useful for scenarios where uninterrupted content delivery is critical, such as using EC2 instances or S3 buckets across different AWS regions for disaster recovery.

#### 3. Field-Level Encryption

- **Purpose:**
  - Field-level encryption enhances security by encrypting specific fields in HTTP POST requests before they are forwarded to your origin.
  - This protects sensitive data (e.g., credit card numbers) across the entire application stack.

- **How it Works:**
  - When a client sends an HTTPS POST request to CloudFront, it specifies which fields (up to 10) should be encrypted.
  - CloudFront uses a specified public key to encrypt these fields before forwarding the request to the origin.
  - Only the origin server, possessing the corresponding private key, can decrypt these fields.
  - This ensures that sensitive information remains encrypted throughout transit and is decrypted only at the trusted origin server.

- **Implementation:**
  - Configure CloudFront to use field-level encryption by specifying which fields to encrypt and which public key to use.
  - This mechanism ensures that even if data interception occurs at the edge locations or during transit, the encrypted fields remain protected until they reach the origin server.

### Summary

These advanced options for CloudFront provide flexibility in managing costs, improving performance, ensuring high availability, and enhancing security. Understanding these features is crucial for optimizing CloudFront distributions based on specific application requirements and operational needs.

<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>

# Real-Time Logs in CloudFront

#### Overview

CloudFront supports real-time logging, allowing you to capture all requests received by CloudFront in near real-time and send them to a Kinesis Data Stream. This feature is invaluable for monitoring, analyzing, and taking immediate actions based on content delivery performance metrics.

#### Workflow

1. **Capturing Requests**: Users make requests to CloudFront, which serves content from edge locations around the world.

2. **Real-Time Logging**: By enabling real-time logs, CloudFront logs each request directly to a Kinesis Data Stream as they occur. This stream can handle large volumes of data in real-time.

3. **Processing Logs**:
   - **Lambda Function**: For near real-time processing, you can configure a Lambda function to process each record from the Kinesis Data Stream as it arrives. This allows for immediate actions or analyses based on incoming requests.
   - **Kinesis Data Firehose**: Alternatively, if you don't require immediate processing, you can use Kinesis Data Firehose to collect logs in batches and deliver them to destinations like Amazon S3, Amazon OpenSearch, or Amazon Redshift for further analysis and long-term storage.

#### Configuration Options

- **Sampling Rate**: You can specify a sampling rate for logging, defining the percentage of requests that CloudFront logs to the Kinesis Data Stream. This is useful for high-traffic endpoints where logging every request might be unnecessary or resource-intensive.
  
- **Filtered Logging**: CloudFront allows you to specify which fields and cache behaviors/path patterns you want to include in the logs sent to the Kinesis Data Stream. This enables targeted monitoring and analysis based on specific criteria, such as requests to certain URL paths (e.g., `/images/*`) or cache behaviors.

#### Use Cases

- **Monitoring Performance**: Real-time logs help monitor the performance of content delivery by tracking metrics like request rates, latency, and error responses as they happen.

- **Security and Compliance**: Enables real-time detection of security threats or compliance violations, allowing for immediate responses or alerts based on suspicious patterns.

- **Operational Insights**: Provides insights into user behavior, traffic patterns, and content consumption trends in real-time, facilitating operational decisions and optimizations.

#### Conclusion

Real-time logging in CloudFront with Kinesis Data Streams offers powerful capabilities for real-time monitoring and analysis of content delivery. It supports flexible configurations for logging only relevant data, processing logs in near real-time with Lambda, and batch processing with Kinesis Data Firehose for scalable analytics and long-term storage. This feature is essential for maintaining visibility and control over CloudFront distributions, ensuring optimal performance and responsiveness to changing conditions.